{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayush-0108/Chat-Bot/blob/institute/institute.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a52d1f1",
      "metadata": {
        "id": "3a52d1f1"
      },
      "source": [
        "EVENTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3b010fb6",
      "metadata": {
        "id": "3b010fb6"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "URL = \"https://iiitdwd.ac.in/events/\"\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (IIITDWD Bot; scraping for educational/demo purposes; contact: youremail@example.com)\"\n",
        "}\n",
        "\n",
        "resp = requests.get(URL, headers=headers)\n",
        "resp.raise_for_status()\n",
        "soup = BeautifulSoup(resp.text, 'html.parser')\n",
        "\n",
        "div_main = soup.find_all('div', class_='text-card-foreground flex flex-col overflow-hidden max-w-md group hover:-translate-y-2 transition-all duration-300 hover:shadow-xl border bg-white rounded-lg shadow-sm py-0 gap-0')\n",
        "\n",
        "event_data = []\n",
        "event_id = 1  # Start from 1\n",
        "\n",
        "for div in div_main:\n",
        "    # Image\n",
        "    image_div = div.find('div', class_='relative h-64 flex-none w-full')\n",
        "    image_tag = image_div.find('img') if image_div else None\n",
        "    image_link = image_tag['src'].strip() if image_tag and image_tag.has_attr('src') else np.nan\n",
        "\n",
        "    # Card content\n",
        "    card_content = div.find('div', class_='px-4 py-6 justify-between flex flex-col h-full')\n",
        "\n",
        "    # Title\n",
        "    title_tag = card_content.find('h2') if card_content else None\n",
        "    title = title_tag.text.strip() if title_tag else np.nan\n",
        "\n",
        "    # Date\n",
        "    date_div = card_content.find('div', class_='flex text-body font-medium text-gray-500 mb-1') if card_content else None\n",
        "    event_date = date_div.text.strip() if date_div else np.nan\n",
        "\n",
        "    # Venue\n",
        "    venue_div = card_content.find('div', class_='flex text-body font-medium text-gray-500') if card_content else None\n",
        "    venue = venue_div.text.strip() if venue_div else np.nan\n",
        "\n",
        "    # Description (same as title)\n",
        "    description = title\n",
        "\n",
        "    # Organizer & registration link (not present)\n",
        "    organizer = np.nan\n",
        "    registration_link = np.nan\n",
        "\n",
        "    # Add row\n",
        "    event_data.append([\n",
        "        event_id,\n",
        "        title,\n",
        "        event_date,\n",
        "        description,\n",
        "        venue,\n",
        "        organizer,\n",
        "        registration_link,\n",
        "        image_link\n",
        "    ])\n",
        "    event_id += 1\n",
        "\n",
        "# Save to CSV\n",
        "columns = ['event_id', 'title', 'event_date', 'description', 'venue', 'organizer', 'registration_link', 'image_link']\n",
        "df = pd.DataFrame(event_data, columns=columns)\n",
        "df.to_csv(\"events.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31fdba9c",
      "metadata": {
        "id": "31fdba9c"
      },
      "source": [
        "RECRUITEMENT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d0a1d3fa",
      "metadata": {
        "id": "d0a1d3fa"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "URL = \"https://iiitdwd.ac.in/careers/\"\n",
        "\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (IIITDWD Bot; scraping for educational/demo purposes; contact: youremail@example.com)\"\n",
        "}\n",
        "\n",
        "resp = requests.get(URL, headers=headers)\n",
        "resp.raise_for_status()\n",
        "soup = BeautifulSoup(resp.text, 'html.parser')\n",
        "\n",
        "div_main = soup.find('div', class_='relative w-full overflow-x-auto rounded-lg border overflow-y-hidden')\n",
        "table = div_main.find('table')\n",
        "\n",
        "rows = []\n",
        "recruitment_id = 1\n",
        "\n",
        "for tr in table.find_all('tr')[1:]:\n",
        "    tds = tr.find_all('td')\n",
        "    if len(tds) < 5:\n",
        "        continue\n",
        "\n",
        "    position = tds[0].get_text(strip=True) if tds[0] else np.nan\n",
        "    department = tds[1].get_text(strip=True) if tds[1] else np.nan\n",
        "    posting_date = tds[2].get_text(strip=True) if tds[2] else np.nan\n",
        "    closing_date = tds[3].get_text(strip=True) if tds[3] else np.nan\n",
        "\n",
        "    link_tag = tds[4].find('a')\n",
        "    job_description = link_tag.get_text(strip=True) if link_tag else np.nan\n",
        "    application_link = link_tag.get('href') if link_tag else np.nan\n",
        "\n",
        "    rows.append([\n",
        "        recruitment_id,\n",
        "        position,\n",
        "        department,\n",
        "        posting_date,\n",
        "        closing_date,\n",
        "        job_description,\n",
        "        application_link\n",
        "    ])\n",
        "    recruitment_id += 1\n",
        "\n",
        "columns = [\n",
        "    'recruitment_id',\n",
        "    'position',\n",
        "    'department',\n",
        "    'posting_date',\n",
        "    'closing_date',\n",
        "    'job_description',\n",
        "    'application_link'\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(rows, columns=columns)\n",
        "df.to_csv(\"recruitments_data.csv\", index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad164a00",
      "metadata": {
        "id": "ad164a00"
      },
      "source": [
        "CONTACTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d1803dd6",
      "metadata": {
        "id": "d1803dd6"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "URL = \"https://iiitdwd.ac.in/contact/\"\n",
        "\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (IIITDWD Bot; scraping for educational/demo purposes; contact: youremail@example.com)\"\n",
        "}\n",
        "\n",
        "resp = requests.get(URL, headers=headers)\n",
        "resp.raise_for_status()\n",
        "soup = BeautifulSoup(resp.text, 'html.parser')\n",
        "\n",
        "divs = soup.find_all('div', class_='flex flex-col gap-4 md:gap-8')\n",
        "contacts = {\"contact_id\": [], \"contact_heading\": [], \"contact\": []}\n",
        "\n",
        "contact_id = 1\n",
        "\n",
        "for div in divs:\n",
        "    contact_heading = div.find('h2').text.strip()\n",
        "    list_items = div.find_all('li')\n",
        "\n",
        "    for contact in list_items:\n",
        "        cont = contact.text.strip()\n",
        "        contacts[\"contact_id\"].append(contact_id)\n",
        "        contacts[\"contact_heading\"].append(contact_heading)\n",
        "        contacts[\"contact\"].append(cont)\n",
        "\n",
        "        contact_id += 1\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(contacts)\n",
        "\n",
        "grouped_df = df.groupby('contact_heading')['contact'].apply(lambda x: '\\n'.join(x)).reset_index()\n",
        "\n",
        "grouped_df.insert(0, 'contact_id', range(1, len(grouped_df) + 1))\n",
        "\n",
        "grouped_df.to_csv(\"contacts.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TENDERS"
      ],
      "metadata": {
        "id": "AFBzb9q6xBpq"
      },
      "id": "AFBzb9q6xBpq"
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "url = \"https://iiitdwd.ac.in/tenders/\"\n",
        "base_url = \"https://iiitdwd.ac.in\"\n",
        "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "\n",
        "response = requests.get(url, headers=headers)\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "table = soup.find(\"table\")\n",
        "rows = table.find_all(\"tr\")\n",
        "data = []\n",
        "\n",
        "for row in rows:\n",
        "    cols = row.find_all([\"td\", \"th\"])\n",
        "    row_data = []\n",
        "    for col in cols:\n",
        "        a_tag = col.find(\"a\", href=True)\n",
        "        if a_tag:\n",
        "            link = urljoin(base_url, a_tag['href'])  # Make it absolute\n",
        "            text = col.get_text(strip=True).replace(a_tag.get_text(strip=True), '').strip()\n",
        "            row_data.append(f\"{text} {link}\".strip())\n",
        "        else:\n",
        "            row_data.append(col.get_text(strip=True))\n",
        "    data.append(row_data)\n",
        "\n",
        "# Make DataFrame\n",
        "df = pd.DataFrame(data[1:], columns=data[0])  # Use first row as headers\n",
        "df.to_csv(\"ActiveTenders.csv\", index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "dm0kuEJdvUix"
      },
      "id": "dm0kuEJdvUix",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bM3qBfJuwm2n"
      },
      "id": "bM3qBfJuwm2n",
      "execution_count": 4,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}