{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayush-0108/Chat-Bot/blob/institute/institute.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a52d1f1",
      "metadata": {
        "id": "3a52d1f1"
      },
      "source": [
        "EVENTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3b010fb6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b010fb6",
        "outputId": "ff38944d-1420-44ef-e574-ce64efb71060"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to events_data_with_images.csv\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "URL = \"https://iiitdwd.ac.in/events/\"\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (IIITDWD Bot; scraping for educational/demo purposes; contact: youremail@example.com)\"\n",
        "}\n",
        "\n",
        "resp = requests.get(URL, headers=headers)\n",
        "resp.raise_for_status()\n",
        "soup = BeautifulSoup(resp.text, 'html.parser')\n",
        "\n",
        "div_main = soup.find_all('div', class_='text-card-foreground flex flex-col overflow-hidden max-w-md group hover:-translate-y-2 transition-all duration-300 hover:shadow-xl border bg-white rounded-lg shadow-sm py-0 gap-0')\n",
        "\n",
        "event_data = []\n",
        "event_id = 1  # Start from 1\n",
        "\n",
        "for div in div_main:\n",
        "    # Image\n",
        "    image_div = div.find('div', class_='relative h-64 flex-none w-full')\n",
        "    image_tag = image_div.find('img') if image_div else None\n",
        "    image_link = image_tag['src'].strip() if image_tag and image_tag.has_attr('src') else np.nan\n",
        "\n",
        "    # Card content\n",
        "    card_content = div.find('div', class_='px-4 py-6 justify-between flex flex-col h-full')\n",
        "\n",
        "    # Title\n",
        "    title_tag = card_content.find('h2') if card_content else None\n",
        "    title = title_tag.text.strip() if title_tag else np.nan\n",
        "\n",
        "    # Date\n",
        "    date_div = card_content.find('div', class_='flex text-body font-medium text-gray-500 mb-1') if card_content else None\n",
        "    event_date = date_div.text.strip() if date_div else np.nan\n",
        "\n",
        "    # Venue\n",
        "    venue_div = card_content.find('div', class_='flex text-body font-medium text-gray-500') if card_content else None\n",
        "    venue = venue_div.text.strip() if venue_div else np.nan\n",
        "\n",
        "    # Description (same as title)\n",
        "    description = title\n",
        "\n",
        "    # Organizer & registration link (not present)\n",
        "    organizer = np.nan\n",
        "    registration_link = np.nan\n",
        "\n",
        "    # Add row\n",
        "    event_data.append([\n",
        "        event_id,\n",
        "        title,\n",
        "        event_date,\n",
        "        description,\n",
        "        venue,\n",
        "        organizer,\n",
        "        registration_link,\n",
        "        image_link\n",
        "    ])\n",
        "    event_id += 1\n",
        "\n",
        "# Save to CSV\n",
        "columns = ['event_id', 'title', 'event_date', 'description', 'venue', 'organizer', 'registration_link', 'image_link']\n",
        "df = pd.DataFrame(event_data, columns=columns)\n",
        "df.to_csv(\"events_data_with_images.csv\", index=False)\n",
        "print(\"Saved to events_data_with_images.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31fdba9c",
      "metadata": {
        "id": "31fdba9c"
      },
      "source": [
        "RECRUITEMENT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d0a1d3fa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0a1d3fa",
        "outputId": "6d428867-f21d-4c2b-9329-23f9054c5249"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to recruitments_data.csv\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "URL = \"https://iiitdwd.ac.in/careers/\"\n",
        "\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (IIITDWD Bot; scraping for educational/demo purposes; contact: youremail@example.com)\"\n",
        "}\n",
        "\n",
        "resp = requests.get(URL, headers=headers)\n",
        "resp.raise_for_status()\n",
        "soup = BeautifulSoup(resp.text, 'html.parser')\n",
        "\n",
        "div_main = soup.find('div', class_='relative w-full overflow-x-auto rounded-lg border overflow-y-hidden')\n",
        "table = div_main.find('table')\n",
        "\n",
        "rows = []\n",
        "recruitment_id = 1\n",
        "\n",
        "for tr in table.find_all('tr')[1:]:\n",
        "    tds = tr.find_all('td')\n",
        "    if len(tds) < 5:\n",
        "        continue\n",
        "\n",
        "    position = tds[0].get_text(strip=True) if tds[0] else np.nan\n",
        "    department = tds[1].get_text(strip=True) if tds[1] else np.nan\n",
        "    posting_date = tds[2].get_text(strip=True) if tds[2] else np.nan\n",
        "    closing_date = tds[3].get_text(strip=True) if tds[3] else np.nan\n",
        "\n",
        "    link_tag = tds[4].find('a')\n",
        "    job_description = link_tag.get_text(strip=True) if link_tag else np.nan\n",
        "    application_link = link_tag.get('href') if link_tag else np.nan\n",
        "\n",
        "    rows.append([\n",
        "        recruitment_id,\n",
        "        position,\n",
        "        department,\n",
        "        posting_date,\n",
        "        closing_date,\n",
        "        job_description,\n",
        "        application_link\n",
        "    ])\n",
        "    recruitment_id += 1\n",
        "\n",
        "columns = [\n",
        "    'recruitment_id',\n",
        "    'position',\n",
        "    'department',\n",
        "    'posting_date',\n",
        "    'closing_date',\n",
        "    'job_description',\n",
        "    'application_link'\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(rows, columns=columns)\n",
        "df.to_csv(\"recruitments_data.csv\", index=False)\n",
        "print(\"Saved to recruitments_data.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad164a00",
      "metadata": {
        "id": "ad164a00"
      },
      "source": [
        "CONTACTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d1803dd6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1803dd6",
        "outputId": "b4ab6761-3785-48de-97f0-22ee267d34c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to contact_page.csv\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "URL = \"https://iiitdwd.ac.in/contact/\"\n",
        "\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (IIITDWD Bot; scraping for educational/demo purposes; contact: youremail@example.com)\"\n",
        "}\n",
        "\n",
        "resp = requests.get(URL, headers=headers)\n",
        "resp.raise_for_status()\n",
        "soup = BeautifulSoup(resp.text, 'html.parser')\n",
        "\n",
        "div_main = soup.find('div', class_='w-full text-title-3 font-normal max-w-xl md:max-w-3xl xl:max-w-5xl mx-auto px-4 md:px-8')\n",
        "\n",
        "page_id = 1\n",
        "heading = div_main.h1.text.strip() if div_main.h1 else np.nan\n",
        "description = div_main.div.text.strip() if div_main.div else np.nan\n",
        "\n",
        "a_tags = div_main.find_all('a', class_='text-main underline')\n",
        "email_link = a_tags[0].get('href') if len(a_tags) > 0 else np.nan\n",
        "map_link = a_tags[1].get('href') if len(a_tags) > 1 else np.nan\n",
        "\n",
        "data = [[page_id, heading, description, email_link, map_link]]\n",
        "\n",
        "columns = ['page_id', 'heading', 'description', 'email_link', 'map_link']\n",
        "df = pd.DataFrame(data, columns=columns)\n",
        "df.to_csv(\"contact_page.csv\", index=False)\n",
        "\n",
        "print(\"Saved to contact_page.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "647aeb3d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "647aeb3d",
        "outputId": "96c4f988-ecae-43be-ce1d-db1435305871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to infrastructure.csv\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "URL = \"https://iiitdwd.ac.in/amenities/\"\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (IIITDWD Bot; scraping for educational/demo purposes; contact: youremail@example.com)\"\n",
        "}\n",
        "\n",
        "resp = requests.get(URL, headers=headers)\n",
        "resp.raise_for_status()\n",
        "soup = BeautifulSoup(resp.text, 'html.parser')\n",
        "\n",
        "divs_main = soup.find_all('div', class_='flex-1 outline-none space-y-4')\n",
        "\n",
        "data = []\n",
        "infra_id = 1\n",
        "\n",
        "for div_main in divs_main:\n",
        "    divs = div_main.find_all('div', class_='bg-white text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm')\n",
        "\n",
        "    for div in divs:\n",
        "        card_header_tag = div.find('div', class_='@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-1.5 px-6 has-[data-slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6')\n",
        "        card_title = card_header_tag.find('div', class_='leading-none !text-title-1 font-semibold text-main flex items-center gap-2')\n",
        "        card_description = card_header_tag.find('div', class_='text-muted-foreground !text-title-3 font-normal')\n",
        "\n",
        "        card_content_para = div.find('div', class_='px-6 space-y-6 text-title-3 font-medium')\n",
        "        description = card_content_para.p.text.strip() if card_content_para.p else np.nan\n",
        "\n",
        "        card_content = card_content_para.find_all('div', class_='bg-background p-4 rounded-lg')\n",
        "\n",
        "        facilities_list = []\n",
        "        location = np.nan\n",
        "\n",
        "        for content in card_content:\n",
        "            header = content.find('h3', class_='font-semibold text-title-2 text-main mb-4')\n",
        "            header_text = header.text.strip() if header else ''\n",
        "\n",
        "            if \"location\" in header_text.lower():\n",
        "                location = content.text.replace(header_text, \"\").strip()\n",
        "            else:\n",
        "                ul_tag = content.find('ul')\n",
        "                if ul_tag:\n",
        "                    li_tags = ul_tag.find_all('li')\n",
        "                    for li in li_tags:\n",
        "                        facilities_list.append(li.text.strip())\n",
        "\n",
        "        facilities = \", \".join(facilities_list) if facilities_list else np.nan\n",
        "\n",
        "        # Attempt to extract image URL\n",
        "        image_div = div.find('img')\n",
        "        image_url = image_div['src'] if image_div and image_div.has_attr('src') else np.nan\n",
        "\n",
        "        name = card_title.text.strip() if card_title else np.nan\n",
        "        infra_type = card_description.text.strip() if card_description else np.nan\n",
        "\n",
        "        data.append([\n",
        "            infra_id,\n",
        "            name,\n",
        "            infra_type,\n",
        "            description,\n",
        "            location,\n",
        "            facilities,\n",
        "            image_url\n",
        "        ])\n",
        "        infra_id += 1\n",
        "\n",
        "columns = ['infrastructure_id', 'name', 'type', 'description', 'location', 'facilities', 'image_url']\n",
        "df = pd.DataFrame(data, columns=columns)\n",
        "df.to_csv(\"infrastructure.csv\", index=False)\n",
        "\n",
        "print(\"Saved to infrastructure.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0d0a71e1",
      "metadata": {
        "id": "0d0a71e1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7a8c4690",
      "metadata": {
        "id": "7a8c4690"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}